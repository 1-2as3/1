"""
æµ‹è¯• stage2_kaist_domain_ft.py çš„æ¨¡å‹ä¸æ•°æ®é›†æ„å»º
- éªŒè¯é…ç½®èƒ½å¦åŠ è½½
- éªŒè¯æ¨¡å‹èƒ½å¦æ„å»º
- éªŒè¯æµ‹è¯•æ•°æ®é›†èƒ½å¦æ„å»ºå¹¶å–å‡ºä¸€ä¸ªæ ·æœ¬
æ³¨æ„ï¼šæ­¤è„šæœ¬ä¸è¿›è¡Œå‰å‘æ¨ç†ï¼Œä»…åšæ„å»ºä¸æ ·æœ¬åŠ è½½æ ¡éªŒ
"""
from mmengine.config import Config
from mmdet.utils import register_all_modules
from mmdet.registry import MODELS, DATASETS
from copy import deepcopy

print("==> 1) æ³¨å†Œæ¨¡å— ...")
register_all_modules(init_default_scope=True)
print("   âœ… æ¨¡å—æ³¨å†Œå®Œæˆ")

print("==> 2) åŠ è½½é…ç½® ...")
cfg_path = 'configs/llvip/stage2_kaist_domain_ft_nodomain.py'
cfg = Config.fromfile(cfg_path)
print("   âœ… é…ç½®åŠ è½½æˆåŠŸ:", cfg_path)

print("==> 3) æ„å»ºæ¨¡å‹ ...")
def _deep_merge(dst: dict, src: dict):
    for k, v in src.items():
        if isinstance(v, dict) and isinstance(dst.get(k), dict):
            _deep_merge(dst[k], v)
        else:
            dst[k] = v
    return dst

def _sanitize_model_cfg(m):
    """ç§»é™¤éƒ¨åˆ†æœªå……åˆ†å®ç°çš„è‡ªå®šä¹‰æ ‡å¿—ï¼Œé¿å…æ„å»ºå¤±è´¥ã€‚
    
    æ³¨æ„ï¼šåœ¨å®é™…è®­ç»ƒæ—¶ï¼ˆtools/train.pyï¼‰ä¸éœ€è¦æ­¤å‡½æ•°ï¼Œ
    å› ä¸º read_base() ä¼šæ­£ç¡®åˆå¹¶é…ç½®ã€‚æ­¤å‡½æ•°ä»…ç”¨äºæµ‹è¯•è„šæœ¬çš„å®¹é”™ã€‚
    
    å½“å‰ç­–ç•¥ï¼šä»…ç§»é™¤ use_domain_lossï¼ˆå°šæœªå®Œæ•´å®ç°ï¼‰
    ä¿ç•™ï¼šuse_macl, use_msp, use_dhnï¼ˆå·²åœ¨ FPN å’Œ StandardRoIHead ä¸­å®ç°ï¼‰
    """
    m = deepcopy(m)
    roi = m.get('roi_head', {})
    # ä»…ç§»é™¤å°šæœªå®ç°çš„æ ‡å¿—
    for k in ['use_domain_loss']:
        if k in roi:
            roi.pop(k)
    m['roi_head'] = roi
    return m

try:
    model_cfg = _sanitize_model_cfg(cfg.model)
    model = MODELS.build(model_cfg)
    if hasattr(model, 'init_weights'):
        try:
            model.init_weights()
        except Exception:
            pass
    print("   âœ… æ¨¡å‹æ„å»ºæˆåŠŸ:", model.__class__.__name__)
except Exception as e:
    print("   âŒ æ¨¡å‹æ„å»ºå¤±è´¥:", e)
    print("   ğŸ›ˆ å½“å‰ cfg.model å†…å®¹:\n", cfg.model)
    print("   ğŸ›ˆ å°è¯•ä½¿ç”¨åŸºç¡€æ¨¡å‹è¿›è¡Œåˆå¹¶åå†æ„å»º ...")
    try:
        base_model_cfg = Config.fromfile('configs/_base_/models/faster_rcnn_r50_fpn.py')['model']
        merged_model = _deep_merge(base_model_cfg, cfg.model)
        merged_model = _sanitize_model_cfg(merged_model)
        model = MODELS.build(merged_model)
        print("   âœ… åˆå¹¶åŸºç¡€æ¨¡å‹åæ„å»ºæˆåŠŸ:", model.__class__.__name__)
    except Exception as e2:
        print("   âŒ åˆå¹¶åŸºç¡€æ¨¡å‹åä»å¤±è´¥:", e2)
        raise

# 3.1 ç»„ä»¶çº§æ„å»ºä¸æ³¨å†Œæ£€æŸ¥ï¼ˆæ¥è‡ª test3 çš„è¦ç‚¹ï¼‰
try:
    from mmdet.registry import MODELS as _MODELS
    fpn_cfg = dict(
        type='FPN', in_channels=[256, 512, 1024, 2048], out_channels=256,
        num_outs=5, use_msp=True, msp_module=dict(type='MSPReweight', channels=256)
    )
    _fpn = _MODELS.build(fpn_cfg)
    print("   âœ… FPN(å«MSP) æ„å»ºé€šè¿‡:", type(_fpn).__name__)
    roi_head_cfg = dict(
        type='StandardRoIHead',
        bbox_roi_extractor=dict(
            type='SingleRoIExtractor', roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),
            out_channels=256, featmap_strides=[4, 8, 16, 32]
        ),
        bbox_head=dict(
            type='Shared2FCBBoxHead', in_channels=256, fc_out_channels=1024, roi_feat_size=7, num_classes=1,
            loss_cls=dict(type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),
            loss_bbox=dict(type='SmoothL1Loss', beta=1.0, loss_weight=1.0)
        ),
        use_macl=True,
        macl_head=dict(type='MACLHead', in_dim=256, proj_dim=128, temperature=0.07, use_dhn=True, dhn_cfg=dict(K=8192, m=0.99))
    )
    _roi_head = _MODELS.build(roi_head_cfg)
    print("   âœ… RoIHead(å«MACL+DHN) æ„å»ºé€šè¿‡:", type(_roi_head).__name__)
    for name in ["MSPReweight", "MACLHead", "DHNSampler"]:
        print(f"   - æ³¨å†Œè¡¨æ£€æŸ¥ MODELS[{name}]:", name in _MODELS.module_dict)
except Exception as e:
    print("   âš ï¸  ç»„ä»¶çº§æ„å»º/æ³¨å†Œæ£€æŸ¥è·³è¿‡:", e)

print("==> 4) æ„å»ºæµ‹è¯•æ•°æ®é›† ...")
# å…¼å®¹ test_dataloader æˆ–æ—§å¼ data['test']
if 'test_dataloader' in cfg:
    ds_cfg = cfg.test_dataloader['dataset'] if isinstance(cfg.test_dataloader, dict) else cfg.test_dataloader.dataset
elif 'data' in cfg and 'test' in cfg.data:
    ds_cfg = cfg.data['test']
else:
    raise RuntimeError('æœªæ‰¾åˆ°æµ‹è¯•æ•°æ®é›†é…ç½®ï¼ˆtest_dataloader/dataset æˆ– data.testï¼‰')

# ç¡®ä¿ä¸å¯ç”¨é…å¯¹æ¨¡å¼ï¼ˆä¸æ ‡å‡† pipeline å…¼å®¹ï¼‰
ds_cfg = ds_cfg.copy()
ds_cfg.setdefault('return_modality_pair', False)

dataset = DATASETS.build(ds_cfg)
print("   âœ… æµ‹è¯•æ•°æ®é›†æ„å»ºæˆåŠŸï¼Œæ€»æ ·æœ¬æ•°:", len(dataset))

print("==> 5) å–ä¸€ä¸ªæ ·æœ¬ä»¥éªŒè¯ pipeline ...")
try:
    item = dataset[0]
    if isinstance(item, dict) and 'inputs' in item and 'data_samples' in item:
        print("   âœ… æ ·æœ¬åŠ è½½æˆåŠŸï¼ŒåŒ…å« keys:", list(item.keys()))
        print("   âœ… inputs shape:", getattr(item['inputs'], 'shape', 'N/A'))
        print("   âœ… data_samples.img_path:", getattr(item['data_samples'], 'img_path', 'N/A'))
    else:
        print("   âš ï¸ æ ·æœ¬è¿”å›æ ¼å¼éæ ‡å‡†ï¼ˆå¯èƒ½å¯ç”¨äº†é…å¯¹æ¨¡å¼æˆ–è‡ªå®šä¹‰è¿”å›ï¼‰ï¼Œkeys:", list(item.keys()) if isinstance(item, dict) else type(item))
except Exception as e:
    print("   âŒ æ ·æœ¬åŠ è½½å¤±è´¥:", e)

print("\nğŸ¯ æ„å»ºéªŒè¯å®Œæˆã€‚")

# 6) å¯é€‰ï¼šä¼˜åŒ–å™¨å‚æ•°/å¯è®­ç»ƒå‚æ•°æ£€æŸ¥ï¼ˆæ¥è‡ª test4 çš„è¦ç‚¹ï¼‰
try:
    import torch
    opt = torch.optim.SGD(model.parameters(), lr=1e-3)
    targets = [
        'neck.msp_module.alpha',
        'roi_head.macl_head.proj.0.weight',
        'roi_head.macl_head.proj.3.weight',  # ä¿®æ­£ï¼šå®é™…æ˜¯ç¬¬3å±‚è€Œéç¬¬2å±‚
        'roi_head.macl_head.tau'  # æ–°å¢ï¼šå¯å­¦ä¹ çš„æ¸©åº¦å‚æ•°
    ]
    found = {t: False for t in targets}
    for n, p in model.named_parameters():
        if p.requires_grad:
            for t in targets:
                if t in n:
                    found[t] = True
    print("\n==> 6) å…³é”®å¯è®­ç»ƒå‚æ•°æ£€æŸ¥:")
    for t, ok in found.items():
        print(f"   {'âœ“' if ok else 'âœ—'} {t}")
except Exception as e:
    print("   âš ï¸  å¯è®­ç»ƒå‚æ•°æ£€æŸ¥è·³è¿‡:", e)

# 7) Person-only å…ƒä¿¡æ¯æ£€æŸ¥ï¼ˆæ¥è‡ª test5 çš„è¦ç‚¹ï¼‰
try:
    from mmdet.datasets import LLVIPDataset, KAISTDataset, M3FDDataset
    print("\n==> 7) æ•°æ®é›† METAINFOï¼ˆclassesï¼‰æ£€æŸ¥:")
    for name, cls in [("LLVIPDataset", LLVIPDataset), ("KAISTDataset", KAISTDataset), ("M3FDDataset", M3FDDataset)]:
        classes = getattr(cls, 'METAINFO', {}).get('classes', ())
        print(f"   - {name}: {classes}")
except Exception as e:
    print("   âš ï¸  å…ƒä¿¡æ¯æ£€æŸ¥è·³è¿‡:", e)
