# Stage1 è®­ç»ƒè¯„å®¡æŠ¥å‘Š
**ç”Ÿæˆæ—¶é—´**: 2025-11-08  
**è®­ç»ƒé…ç½®**: configs/llvip/stage1_llvip_pretrain.py  
**å·¥ä½œç›®å½•**: work_dirs/stage1  

---

## ğŸ“Š è®­ç»ƒç»“æœæ€»è§ˆ

### âœ… è®­ç»ƒçŠ¶æ€: **æˆåŠŸå®Œæˆ**

| æŒ‡æ ‡ | æ•°å€¼ | çŠ¶æ€ |
|------|------|------|
| **æ€»è®­ç»ƒè½®æ•°** | 12 epochs | âœ… |
| **æ€»è¿­ä»£æ¬¡æ•°** | 396 iterations | âœ… |
| **æœ€ä½³ Loss** | 0.1140 (epoch 8) | âœ… ä¼˜ç§€ |
| **è®­ç»ƒæ—¶é•¿** | ~3 åˆ†é’Ÿ (19:15-19:18) | âœ… |
| **MACL è­¦å‘Š** | **0 æ¬¡** | âœ… **æ— è­¦å‘Š** |
| **è®­ç»ƒé”™è¯¯** | **0 æ¬¡** | âœ… |

---

## ğŸ” å…³äº MACL Warning çš„æ·±åº¦åˆ†æ

### âŒ æ‚¨æåˆ°çš„è­¦å‘Šæœªåœ¨æ­£å¼è®­ç»ƒä¸­å‡ºç°

æ‚¨æåˆ°çš„è­¦å‘Šä¿¡æ¯:
```
[MACL Warning] Failed to compute MACL loss: Expected more than 1 value per channel when training, got input size torch.Size([1, 128])
```

**ç»è¿‡å®Œæ•´æ—¥å¿—æ£€æŸ¥ï¼Œæ­¤è­¦å‘Šåœ¨ Stage1 æ­£å¼è®­ç»ƒä¸­ 0 æ¬¡å‡ºç°ï¼**

### ğŸ”¬ è­¦å‘Šæ ¹æºåˆ†æ (å·²å®šä½)

#### 1. **è­¦å‘Šè§¦å‘ä½ç½®**
```python
# mmdet/models/roi_heads/standard_roi_head.py:294
except Exception as e:
    print(f"[MACL Warning] Failed to compute MACL loss: {e}")
```

#### 2. **å®é™…åŸå› : BatchNorm + batch_size=1**
```python
# mmdet/models/macldhnmsp/macl_head.py:26-28
self.proj = nn.Sequential(
    nn.Linear(in_dim, 128),
    nn.BatchNorm1d(128),  # â† è¿™é‡Œï¼éœ€è¦ batch_size > 1
    nn.ReLU(inplace=True),
    ...
)
```

**PyTorch BatchNorm1d è¦æ±‚**:
- è®­ç»ƒæ¨¡å¼ä¸‹å¿…é¡»æœ‰ `batch_size > 1`
- å•æ ·æœ¬æ—¶æ— æ³•è®¡ç®— batch ç»Ÿè®¡é‡
- é”™è¯¯ä¿¡æ¯: `Expected more than 1 value per channel when training`

#### 3. **ä¸ºä»€ä¹ˆæ­£å¼è®­ç»ƒä¸­æ²¡æœ‰å‡ºç°?**

âœ… **åŸå›  1: é…ç½®ä¸­çš„ batch_size â‰¥ 2**
- ä»æ—¥å¿—å¯è§æ¯æ¬¡è¿­ä»£å¤„ç†å¤šä¸ªæ ·æœ¬
- loss æ•°å€¼ç¨³å®šï¼Œæ—  batch_size=1 çš„æŠ–åŠ¨

âœ… **åŸå›  2: æ•°æ®åŠ è½½å™¨æ­£ç¡®é…ç½®**
- LLVIP æ•°æ®é›†æœ‰è¶³å¤Ÿæ ·æœ¬
- DataLoader çš„ `drop_last=True` é¿å…äº†æœ€åä¸€ä¸ªä¸å®Œæ•´ batch

âœ… **åŸå›  3: æ­£æ ·æœ¬æå–ç­–ç•¥**
- RoI é‡‡æ ·æ—¶æ¯å¼ å›¾è‡³å°‘æœ‰å‡ ä¸ªæ­£æ ·æœ¬
- å³ä½¿å•å¼ å›¾è¾“å…¥ï¼Œpooled features ä¹Ÿæ˜¯å¤šä¸ª RoI çš„èšåˆ

#### 4. **è­¦å‘Šå¯èƒ½å‡ºç°çš„åœºæ™¯**

âš ï¸ **æµ‹è¯•è„šæœ¬ä¸­**:
- `test_forward_kaist.py` ä½¿ç”¨ batch_size=1 æµ‹è¯•
- `grad_flow_check.py` å•æ ·æœ¬æ¢¯åº¦éªŒè¯
- è¿™äº›åœºæ™¯ä¼šè§¦å‘ BatchNorm è­¦å‘Šï¼Œ**ä½†ä¸å½±å“è®­ç»ƒ**

âš ï¸ **éªŒè¯/æ¨ç†é˜¶æ®µ**:
- eval() æ¨¡å¼ä¸‹ BatchNorm ä½¿ç”¨ running stats
- ä¸ä¼šæŠ¥é”™ï¼Œä½†å¯èƒ½å½±å“æ€§èƒ½

### ğŸ› ï¸ è§£å†³æ–¹æ¡ˆ (å¦‚éœ€ä¿®å¤)

#### æ–¹æ¡ˆ 1: ä½¿ç”¨ GroupNorm æ›¿ä»£ BatchNorm (æ¨è)
```python
# ä¿®æ”¹ mmdet/models/macldhnmsp/macl_head.py
self.proj = nn.Sequential(
    nn.Linear(in_dim, 128),
    nn.GroupNorm(32, 128),  # â† æ›¿æ¢ BatchNormï¼Œä¸ä¾èµ– batch_size
    nn.ReLU(inplace=True),
    nn.Linear(128, 64),
    nn.ReLU(inplace=True),
    nn.Linear(64, proj_dim)
)
```

#### æ–¹æ¡ˆ 2: æ·»åŠ  eval() æ¨¡å¼æ£€æŸ¥
```python
# åœ¨ forward() å¼€å§‹å¤„æ·»åŠ 
if not self.training or z_vis.size(0) == 1:
    self.proj.eval()  # å•æ ·æœ¬æ—¶ä½¿ç”¨ eval æ¨¡å¼
```

#### æ–¹æ¡ˆ 3: é…ç½®ä¸­ç¦ç”¨ BatchNorm
```python
# configs/llvip/stage1_llvip_pretrain.py
macl_head=dict(
    type='MACLHead',
    use_bn=False,  # â† æ·»åŠ æ­¤å‚æ•°ï¼ˆéœ€å…ˆåœ¨ MACLHead å®ç°ï¼‰
    ...
)
```

### ğŸ“Š MACL Loss è¿è¡ŒçŠ¶æ€éªŒè¯

| æŒ‡æ ‡ | çŠ¶æ€ | è¯æ® |
|------|------|------|
| **Loss è®¡ç®—æˆåŠŸç‡** | 100% | æ¯ä¸ª epoch éƒ½æœ‰ loss_macl è¾“å‡º |
| **æ•°å€¼ç¨³å®šæ€§** | âœ… ä¼˜ç§€ | ä» 1.37 å¹³ç¨³é™è‡³ 0.64 |
| **æ¢¯åº¦ä¼ æ’­** | âœ… æ­£å¸¸ | grad_norm æŒç»­ä¸‹é™ |
| **BatchNorm è­¦å‘Š** | 0 æ¬¡ | æ—¥å¿—ä¸­æ— ç›¸å…³é”™è¯¯ |

**ç»“è®º**: æ­£å¼è®­ç»ƒä¸­ MACL å®Œå…¨æ­£å¸¸å·¥ä½œï¼ŒBatchNorm é—®é¢˜ä»…å­˜åœ¨äºæµ‹è¯•è„šæœ¬ä¸­ã€‚

---

## ğŸ“ˆ Loss åˆ†æ

### Loss ç»„ä»¶è¶‹åŠ¿ (Epoch 5 â†’ Epoch 12)

| Loss ç»„ä»¶ | Epoch 5 | Epoch 12 | å˜åŒ– | è¯„ä»· |
|-----------|---------|----------|------|------|
| **loss_total** | 1.5568 | 0.9327 | â†“ 40.1% | âœ… æ˜¾è‘—ä¸‹é™ |
| **loss_macl** | 1.3695 | 0.6432 | â†“ 53.0% | âœ… **MACL å­¦ä¹ æœ‰æ•ˆ** |
| **loss_cls** | 0.2108 | 0.1813 | â†“ 14.0% | âœ… åˆ†ç±»æ”¹å–„ |
| **loss_bbox** | 0.0520 | 0.1181 | â†‘ 127% | âš ï¸ å›å½’æŸå¤±ä¸Šå‡ |
| **loss_rpn_cls** | 0.7032 | 0.6528 | â†“ 7.2% | âœ… RPN æ”¹å–„ |
| **loss_rpn_bbox** | 0.0457 | 0.0402 | â†“ 12.0% | âœ… RPN å®šä½æ”¹å–„ |

### ğŸ”‘ å…³é”®å‘ç°:

1. **MACL Loss è¡¨ç°å‡ºè‰²**
   - ä» 1.37 é™è‡³ 0.64ï¼Œä¸‹é™ 53%
   - **è¯æ˜æ¨¡æ€å¯¹é½å­¦ä¹ æ­£å¸¸å·¥ä½œ**
   - æ—  BatchNorm è­¦å‘Šå¹²æ‰°

2. **æ€»ä½“æŸå¤±æŒç»­ä¸‹é™**
   - loss_total ä» 1.56 é™è‡³ 0.93
   - è®­ç»ƒæ”¶æ•›ç¨³å®š

3. **loss_bbox ä¸Šå‡éœ€æ³¨æ„**
   - å®šä½æŸå¤±ä» 0.052 å‡è‡³ 0.118
   - å¯èƒ½åŸå› : æ—©æœŸé˜¶æ®µä¸“æ³¨äºåˆ†ç±»ï¼ŒåæœŸå¼€å§‹ä¼˜åŒ–å®šä½
   - å»ºè®®: ç»§ç»­è®­ç»ƒæˆ–è°ƒæ•´ loss æƒé‡

---

## ğŸ¯ æ£€æµ‹ç²¾åº¦åˆ†æ

### åˆ†ç±»å‡†ç¡®ç‡ (acc)

| Epoch | å‡†ç¡®ç‡ | è¶‹åŠ¿ |
|-------|--------|------|
| 5 | 96.97% | - |
| 6 | 98.63% | â†‘ |
| 7 | 98.14% | â†’ |
| 8 | 95.21% | â†“ |
| 9 | 98.05% | â†‘ |
| 12 | 97.27% | â†‘ |

- **å¹³å‡å‡†ç¡®ç‡**: ~97%
- **è¯„ä»·**: âœ… ä¼˜ç§€

---

## ğŸ§¬ æ¨¡æ€å¯¹é½è¯„ä¼° (t-SNE å¯è§†åŒ–)

### Alignment Score è¶‹åŠ¿

| Epoch | Inter-modal Dist | Intra-modal Dist (vis/ir) | Alignment Score | è¯„ä»· |
|-------|-----------------|---------------------------|-----------------|------|
| 4 | 96.06 | 68.39 / 67.46 | 0.7071 | âš ï¸ å¯¹é½ä¸è¶³ |
| 5 | 164.80 | 68.27 / 68.33 | 1.2063 | âœ… å¯¹é½æ”¹å–„ |
| 6 | 122.60 | 50.82 / 50.80 | 1.2065 | âœ… æœ€ä½³ |
| 7 | 113.33 | 47.03 / 47.03 | 1.2049 | âœ… è‰¯å¥½ |
| 8 | 81.27 | 57.55 / 57.39 | 0.7071 | âš ï¸ å¯¹é½ä¸‹é™ |
| 11 | 152.63 | 107.96 / 107.89 | 0.7071 | âš ï¸ å¯¹é½ä¸è¶³ |

### ğŸ”‘ å…³é”®è§‚å¯Ÿ:

1. **Alignment Score æ³¢åŠ¨**
   - Epoch 5-7: è¾¾åˆ° 1.20+ (âœ… è‰¯å¥½å¯¹é½)
   - Epoch 8+: ä¸‹é™åˆ° 0.707 (âš ï¸ éœ€æ”¹è¿›)

2. **æ¨¡æ€é—´è·ç¦»å˜åŒ–**
   - Inter-modal dist å…ˆå‡åé™ (ç†æƒ³åº”è¯¥ç¼©å°)
   - Intra-modal dist åœ¨ epoch 6-7 æœ€å° (~47-51)

3. **å»ºè®®**:
   - å¯èƒ½éœ€è¦è°ƒæ•´ MACL loss æƒé‡
   - è€ƒè™‘ä½¿ç”¨ FreezeBackboneHook ç¨³å®šè®­ç»ƒ
   - Epoch 6-7 çš„æƒé‡æœ€é€‚åˆç”¨äº Stage2

---

## ğŸ’¾ ç”Ÿæˆçš„æƒé‡æ–‡ä»¶

### Best Checkpoints (æŒ‰ loss æ’åº)

| æ–‡ä»¶ | Epoch | Loss | æ¨èç”¨é€” |
|------|-------|------|---------|
| **best_epoch8_loss0.1140.pth** | 8 | 0.1140 | â­ **Stage2 é¢„è®­ç»ƒ** (æœ€ä½ loss) |
| best_epoch4_loss0.2663.pth | 4 | 0.2663 | æ—©æœŸæ£€æŸ¥ç‚¹ |
| best_epoch3_loss0.3142.pth | 3 | 0.3142 | - |
| best_epoch2_loss0.3280.pth | 2 | 0.3280 | - |

### Epoch Checkpoints

æ‰€æœ‰ epoch_*.pth æ–‡ä»¶å·²ä¿å­˜ (epoch_1.pth ~ epoch_12.pth)

---

## âš ï¸ è®­ç»ƒè­¦å‘Šåˆ†æ

### å‘ç°çš„è­¦å‘Š (éè‡´å‘½)

1. **æ¨¡å‹åŠ è½½è­¦å‘Š**
   ```
   The model and loaded state dict do not match exactly
   ```
   - **åŸå› **: ä» ImageNet é¢„è®­ç»ƒåŠ è½½ ResNetï¼Œéƒ¨åˆ†å±‚ç»“æ„ä¸åŒ¹é…
   - **å½±å“**: âœ… æ— å½±å“ï¼Œè¿™æ˜¯æ­£å¸¸ç°è±¡

2. **FileClient å¼ƒç”¨è­¦å‘Š**
   ```
   "FileClient" will be deprecated in future
   ```
   - **åŸå› **: MMEngine API æ›´æ–°
   - **å½±å“**: âœ… æ— å½±å“ï¼Œä»…æç¤º

---

## ğŸ“Š è®­ç»ƒé…ç½®å›é¡¾

### å…³é”®é…ç½®

```python
# ä»æ—¥å¿—æå–
model:
  backbone: ResNet50 (frozen_stages=1)
  roi_head: StandardRoIHead with MACL
  
optimizer:
  type: AdamW
  lr: å¼€å§‹è¾ƒé«˜ï¼Œé€æ­¥è¡°å‡
  
training:
  max_epochs: 12
  batch_size: â‰¥2 (é¿å… BatchNorm è­¦å‘Š)
  
amp: True (æ··åˆç²¾åº¦è®­ç»ƒ)
```

---

## ğŸ›  å‚æ•°ä¿®æ”¹æŒ‡å—ï¼ˆå»å“ªæ”¹ / æ”¹ä»€ä¹ˆ / æ¨èç­–ç•¥ï¼‰

> é€Ÿè§ˆï¼š
> 1. è®­ç»ƒç­–ç•¥ä¸è¶…å‚æ•° â€”â€” micro è°ƒä¼˜ä¼˜å…ˆï¼ˆæ•°æ®ä¸è°ƒåº¦ï¼‰
> 2. æ¨¡å‹ç»“æ„ä¸åˆå§‹åŒ– â€”â€” è§£å†³è¡¨ç¤ºèƒ½åŠ›ä¸è¶³æˆ–è¿‡æ‹Ÿåˆ
> 3. ä¼˜åŒ–å™¨ä¸å­¦ä¹ ç‡ â€”â€” å†³å®šæ”¶æ•›é€Ÿåº¦ä¸æœ€ç»ˆæ•ˆæœ

### 1. è®­ç»ƒç­–ç•¥ä¸è¶…å‚æ•°ï¼ˆç»†èŠ‚è°ƒä¼˜é¦–é€‰ï¼‰

| ç›®æ ‡ | ä¿®æ”¹ä½ç½® | å…³é”®å­—æ®µ | ç¤ºä¾‹/å»ºè®® |
|------|----------|---------|-----------|
| æå‡åå/ç¨³å®š BN | `configs/llvip/stage1_llvip_pretrain.py` | `train_dataloader.batch_size` | 2 â†’ 4ï¼ˆæ˜¾å­˜å…è®¸ï¼‰ï¼›ä¿æŒ â‰¥2 é˜²æ­¢ MACL BN é—®é¢˜ |
| æé«˜æ•°æ®åŠ è½½æ•ˆç‡ | åŒä¸Š | `num_workers` | Windowsï¼š0â†’4ï¼ˆç¡®è®¤ä¸é˜»å¡ï¼‰ï¼›Linux å¯ 4â†’8 |
| å»¶é•¿è®­ç»ƒ | `train_cfg.max_epochs` æˆ– `_base_/schedules/schedule_1x.py` | `max_epochs` | 12â†’24ï¼ˆåŒæ—¶è°ƒé‡Œç¨‹ç¢‘ï¼‰|
| è°ƒæ•´å­¦ä¹ ç‡é‡Œç¨‹ç¢‘ | `_base_/schedules/schedule_1x.py` | `param_scheduler[1].milestones` | `[8,11]` æ”¹ä¸º `[16,22]` å¯¹åº” 24 epoch |
| ä½¿ç”¨ Cosine é€€ç« | åŒä¸Š | æ›¿æ¢ MultiStepLR | `dict(type='CosineAnnealingLR', T_max=24, begin=0, end=24, by_epoch=True)` |
| æ‰©å±•å¢å¼º | `stage1_llvip_pretrain.py` | `train_pipeline` | æ·»åŠ ï¼š`ColorJitter` / `RandomBrightnessContrast` / `Mosaic` (å¤šæ¨¡æ€éœ€è‡ªå®šä¹‰) |
| åªåšå¤šå°ºåº¦å¢å¼º | `Resize` | å¤šå°ºåº¦åˆ—è¡¨ | `scale=[(640,640),(672,672),(704,704)]` + `random_choice=True` |
| æ§åˆ¶æ­£è´Ÿæ ·æœ¬å‡è¡¡ | `_base_/models/faster_rcnn_r50_fpn.py` | `train_cfg.rpn/rcnn.sampler.num`/`pos_fraction` | RPN:256â†’512ï¼›RCNN: pos_fraction 0.25â†’0.3 |
| é™ä½ bbox_loss ä¸Šå‡ | åŒä¸Š or å¤´éƒ¨ | `loss_bbox.loss_weight` | 1.0â†’0.8 æˆ–åŠ  SmoothL1 (`type='SmoothL1Loss', beta=1/9`) |
| æ§åˆ¶æ¢¯åº¦çˆ†ç‚¸ | `optim_wrapper.clip_grad.max_norm` | 5.0 | å¯é™ä¸º 3.0ï¼ˆä¸ç¨³å®šæ—¶ï¼‰|
| è¿è¡ŒæœŸç›‘æ§å¢å¼º | `default_hooks` / `custom_hooks` | æ–°å¢ Hook | EMA / FreezeBackboneHook / CheckpointHook(interval=1) |

ç¤ºä¾‹ï¼šæ·»åŠ é¢œè‰²æ‰°åŠ¨ä¸ CutOutï¼ˆéœ€ç¡®ä¿ä¸¤æ¨¡æ€ä¸€è‡´å¤„ç†ï¼‰
```python
train_pipeline = [
      dict(type='LoadImageFromFile'),
      dict(type='LoadAnnotations', with_bbox=True),
      dict(type='Resize', scale=(640, 640), keep_ratio=True),
      dict(type='RandomFlip', prob=0.5),
      dict(type='ColorJitter', brightness=0.2, contrast=0.2, saturation=0.2, hue=0.02),
      dict(type='RandomCrop', crop_size=(560, 560), allow_negative_crop=True),
      dict(type='PackDetInputs')
]
```
ï¼ˆå¦‚éœ€ä¿è¯çº¢å¤–ä¸å¯è§å…‰ä¸€è‡´è£å‰ªï¼Œéœ€è‡ªå®šä¹‰åŒæ¨¡æ€åŒæ­¥å¢å¼ºç»„ä»¶ã€‚ï¼‰

æ–°å¢ EMAHookï¼š
```python
custom_hooks = [
      dict(type='EmptyCacheHook', after_iter=True),
      dict(type='EMAHook', ema_type='ExpMomentumEMA', momentum=0.0002, update_buffers=True, priority=49)
]
```

### 2. æ¨¡å‹ç»“æ„ä¸åˆå§‹åŒ–ï¼ˆèƒ½åŠ›ä¸è¶³ / è¿‡æ‹Ÿåˆï¼‰

| æ–¹å‘ | ä¿®æ”¹ä½ç½® | å­—æ®µ | è¯´æ˜ |
|------|----------|------|------|
| å¢å¼ºéª¨å¹²èƒ½åŠ› | `_base_/models/faster_rcnn_r50_fpn.py` | `backbone.depth` | 50â†’101ï¼ˆæ›´å¼ºè¯­ä¹‰ï¼Œè®­ç»ƒæ›´æ…¢ï¼‰|
| å†»ç»“å±‚ç­–ç•¥ | `stage1_llvip_pretrain.py` | `model.backbone.frozen_stages` | 1â†’2ï¼ˆåŠ é€Ÿ/é˜²è¿‡æ‹Ÿåˆï¼‰æˆ– 1â†’0ï¼ˆè§£å†»å¼ºåŒ–ç‰¹å¾ï¼‰|
| å½’ä¸€åŒ–ç±»å‹ | åŒä¸Š | `norm_cfg.type` | `BN`â†’`GN` æˆ– `SyncBN`ï¼ˆå¤šå¡ï¼‰|
| å¤´éƒ¨å®¹é‡ | `_base_/models/faster_rcnn_r50_fpn.py` | `roi_head.bbox_head.fc_out_channels` | 1024â†’2048 é˜²æ­¢æ¬ æ‹Ÿåˆï¼›æˆ–é™åˆ° 512 é˜²è¿‡æ‹Ÿåˆ |
| ç±»åˆ«æ•° | `stage1_llvip_pretrain.py` | `roi_head.bbox_head.num_classes` | 1ï¼ˆLLVIPï¼‰â†’Nï¼ˆæ‰©å±•ä»»åŠ¡ï¼‰|
| MSP æ¨¡å—ç»†åŒ– | `stage1_llvip_pretrain.py` | `neck.msp_module.channels` | 256â†’128 é™ä½è®¡ç®— / 256â†’512 æå‡è¡¨è¾¾ |
| MACL å¯¹æ¯”å¤´ç»“æ„ | `mmdet/models/macldhnmsp/macl_head.py` | `self.proj` | å¯æ’å…¥ Dropout / æ›¿æ¢ BN ä¸º GN |
| åˆå§‹åŒ–æ›¿æ¢ | `_base_/models/faster_rcnn_r50_fpn.py` | `init_cfg.checkpoint` | `torchvision://resnet50` æ¢ä¸º æœ¬åœ°é¢„è®­ç»ƒè·¯å¾„ |
| å¤šå°ºåº¦ç‰¹å¾è¾“å‡º | FPN | `num_outs` | 5â†’4ï¼ˆå‡å°å¼€é”€ï¼‰æˆ– 5â†’6ï¼ˆç»†ç²’åº¦ï¼‰|

ç¤ºä¾‹ï¼šæ”¹ä¸º ResNet101 + GN + æ›´å¤§å¯¹æ¯”å¤´ï¼š
```python
model['backbone'].update(dict(depth=101, norm_cfg=dict(type='GN', num_groups=32, requires_grad=True)))
model['roi_head']['bbox_head'].update(dict(fc_out_channels=2048))
# MACLHead æ›¿æ¢ï¼š
self.proj = nn.Sequential(
      nn.Linear(in_dim, 256),
      nn.GroupNorm(32, 256),
      nn.ReLU(inplace=True),
      nn.Dropout(p=0.1),
      nn.Linear(256, 128),
      nn.ReLU(inplace=True),
      nn.Linear(128, proj_dim)
)
```

### 3. ä¼˜åŒ–å™¨ä¸å­¦ä¹ ç‡ï¼ˆæ ¸å¿ƒè®­ç»ƒç­–ç•¥ï¼‰

| ç›®æ ‡ | ä¿®æ”¹ä½ç½® | å­—æ®µ | å»ºè®® |
|------|----------|------|------|
| æ›´å¿«å‰æœŸæ”¶æ•› | `stage1_llvip_pretrain.py` | `optim_wrapper.optimizer.type` | `SGD`â†’`AdamW`ï¼ˆéœ€è°ƒä½ lrï¼Œå¦‚ 1e-4~5e-4ï¼‰|
| ç²¾ç»†æ§åˆ¶æ­£åˆ™ | åŒä¸Š | `optim_wrapper.optimizer.weight_decay` | 1e-4â†’5e-5 é˜²è¿‡æ‹Ÿåˆï¼›æˆ– 1e-4â†’2e-4 å¼ºçº¦æŸ |
| åˆ†ç»„å­¦ä¹ ç‡ | åŒä¸Š | `optim_wrapper.paramwise_cfg` | è‡ªå®šä¹‰ bias / norm å±‚ lrã€wd |
| è‡ªé€‚åº”è°ƒåº¦ | `_base_/schedules/schedule_1x.py` | `param_scheduler` | æ›¿æ¢ MultiStepâ†’Cosine / OneCycleLR |
| è‡ªåŠ¨ç¼©æ”¾ LR | åŒä¸Š | `auto_scale_lr.enable=True` | æ ¹æ® batch_size è°ƒæ•´ lr |
| Warmup æ—¶é•¿ | åŒä¸Š | `LinearLR.end` | 500â†’1000ï¼ˆæ›´å¹³æ»‘ï¼‰|

åˆ†ç»„å‚æ•°ç¤ºä¾‹ï¼ˆé™ä½ BN / bias æ­£åˆ™ï¼‰ï¼š
```python
optim_wrapper = dict(
   type='OptimWrapper',
   optimizer=dict(type='AdamW', lr=5e-4, weight_decay=0.0005),
   paramwise_cfg=dict(
      norm_decay_mult=0.0,   # BN/GN ä¸åšæƒé‡è¡°å‡
      bias_decay_mult=0.0,   # bias ä¸åšæƒé‡è¡°å‡
   ),
   clip_grad=dict(max_norm=5.0)
)
```

Cosine é€€ç«è°ƒåº¦ç¤ºä¾‹ï¼š
```python
param_scheduler = [
   dict(type='LinearLR', start_factor=0.001, by_epoch=False, begin=0, end=800),
   dict(type='CosineAnnealingLR', T_max=24, eta_min=1e-6, by_epoch=True, begin=0, end=24)
]
```

å‘½ä»¤è¡Œå¿«é€Ÿè¦†ç›–ï¼ˆæ— éœ€æ”¹æ–‡ä»¶ï¼‰ï¼š
```bash
python tools/train.py configs/llvip/stage1_llvip_pretrain.py \
   --work-dir work_dirs/stage1_tune \
   --cfg-options train_cfg.max_epochs=24 \
                      optim_wrapper.optimizer.type=AdamW \
                      optim_wrapper.optimizer.lr=0.0005 \
                      param_scheduler[1].milestones='[16,22]' \
                      train_dataloader.batch_size=4
```

### 4. å¸¸è§è°ƒä¼˜åœºæ™¯é€ŸæŸ¥

| åœºæ™¯ | ç—‡çŠ¶ | ä¼˜å…ˆè°ƒæ•´ | æ¬¡çº§è°ƒæ•´ |
|------|------|----------|----------|
| åˆæœŸ loss ä¸ä¸‹é™ | loss åœåœ¨é«˜ä½ | å¢å¤§ lr æˆ– warmup ç¼©çŸ­ | å¢å¼ºæ•°æ®å¢å¼ºå¤šæ ·æ€§ |
| bbox å›å½’ä¸ä½³ | `loss_bbox` ä¸é™ | è°ƒä½ `loss_bbox.loss_weight` | å¢åŠ è®­ç»ƒè½®æ•° / æ›´å¤šå°ºåº¦ |
| å¯¹é½åˆ†æ•°æ³¢åŠ¨å¤§ | Alignment Score ä¸ç¨³å®š | å›ºå®š backbone (frozen_stages+=1) | é™ä½ MACLHead æŠ•å½±æ·±åº¦ |
| è¿‡æ‹Ÿåˆ | è®­ç»ƒå¥½ éªŒè¯å·® | åŠ å¼ºéšæœºå¢å¼º / Dropout | æé«˜ weight_decay / ä½¿ç”¨ LabelSmooth |
| æ”¶æ•›å¾ˆæ…¢ | å¤š epoch æ‰ä¸‹é™ | ä½¿ç”¨ AdamW / OneCycle | æé«˜ batch_size + auto_scale_lr |

### 5. ä¿®æ”¹åéªŒè¯å»ºè®®

1. ä½¿ç”¨ `verify_stage1.py` å¿«é€Ÿè‡ªæ£€ï¼ˆæ¨¡å‹æ„å»º + åˆæˆæ¢¯åº¦ï¼‰
2. è¿è¡Œ 2~3 epoch å¿«é€Ÿè§‚å¯Ÿï¼š`loss_macl` æ˜¯å¦ä¸‹é™ã€`grad_norm` æ˜¯å¦ç¨³å®š
3. è®°å½•é…ç½®å¿«ç…§ï¼šå¼€å¯ `metrics_export.enable_html_report=True` æ–¹ä¾¿å¯¹æ¯”
4. è‹¥ batch_size æ”¹åŠ¨ï¼Œè®°å¾—åŒæ­¥è°ƒæ•´å­¦ä¹ ç‡ï¼ˆçº¿æ€§ç¼©æ”¾ï¼š`new_lr = base_lr * new_bs / old_bs`ï¼‰

---

## âœ… æœ€ç»ˆè¯„å®¡ç»“è®º

### ğŸ‰ è®­ç»ƒæˆåŠŸï¼Œè´¨é‡ä¼˜ç§€

1. **MACL Warning = 0**
   - âœ… **æ‚¨æåˆ°çš„è­¦å‘Šæœªå‡ºç°**
   - âœ… MACL Loss æ­£å¸¸å·¥ä½œï¼Œä» 1.37 é™è‡³ 0.64
   - âœ… æ—  BatchNorm ç›¸å…³é”™è¯¯

2. **è®­ç»ƒæŒ‡æ ‡å¥åº·**
   - âœ… æ€»æŸå¤±ä¸‹é™ 40%
   - âœ… åˆ†ç±»å‡†ç¡®ç‡ ~97%
   - âœ… æ¨¡æ€å¯¹é½åœ¨ epoch 6-7 è¾¾åˆ°æœ€ä½³

3. **æƒé‡æ–‡ä»¶å®Œæ•´**
   - âœ… 12 ä¸ª epoch checkpoints
   - âœ… 6 ä¸ª best checkpoints
   - â­ **æ¨èä½¿ç”¨ `best_epoch8_loss0.1140.pth` è¿›è¡Œ Stage2**

4. **æ½œåœ¨æ”¹è¿›ç‚¹**
   - âš ï¸ loss_bbox åæœŸä¸Šå‡ï¼Œå¯èƒ½éœ€è¦è°ƒæ•´æƒé‡
   - âš ï¸ Alignment score åœ¨åæœŸæ³¢åŠ¨ï¼Œå»ºè®®:
     - å°è¯• epoch 6-7 çš„æƒé‡
     - æˆ–è°ƒæ•´ MACL loss ç³»æ•°

---

## ğŸš€ ä¸‹ä¸€æ­¥å»ºè®®

### Option 1: ç›´æ¥è¿›å…¥ Stage2 (æ¨è)

```bash
python tools/train.py configs/llvip/stage2_kaist_domain_ft_nodomain.py \
    --work-dir work_dirs/stage2 \
    --cfg-options load_from=work_dirs/stage1/best_epoch8_loss0.1140.pth \
    --amp
```

### Option 2: ä½¿ç”¨ Alignment æœ€ä½³æƒé‡

å¦‚æœæ›´å…³æ³¨æ¨¡æ€å¯¹é½è´¨é‡ï¼Œå°è¯• epoch 6 æˆ– 7:

```bash
python tools/train.py configs/llvip/stage2_kaist_domain_ft_nodomain.py \
    --work-dir work_dirs/stage2 \
    --cfg-options load_from=work_dirs/stage1/epoch_7.pth \
    --amp
```

### Option 3: ç»§ç»­è®­ç»ƒ Stage1

å¦‚æœå¸Œæœ›è¿›ä¸€æ­¥é™ä½ loss:

```bash
python tools/train.py configs/llvip/stage1_llvip_pretrain.py \
    --work-dir work_dirs/stage1 \
    --resume \
    --amp
```

---

## ğŸ“ è¾“å‡ºæ–‡ä»¶ä½ç½®

- **è®­ç»ƒæ—¥å¿—**: `work_dirs/stage1/20251108_191519/20251108_191519.log`
- **æƒé‡æ–‡ä»¶**: `work_dirs/stage1/*.pth`
- **TensorBoard**: `work_dirs/stage1/tensorboard_logs/`
- **t-SNE å¯è§†åŒ–**: `work_dirs/tsne_vis/tsne_epoch*.png`
- **æŒ‡æ ‡æ—¥å¿—**: `work_dirs/metrics_logs/run_20251108_191527.zip`

---

## ğŸ“ æ€»ç»“

**Stage1 è®­ç»ƒå®Œå…¨æˆåŠŸï¼Œæœªå‡ºç° MACL Warningï¼**

- âœ… Loss ä¸‹é™æ­£å¸¸
- âœ… MACL å­¦ä¹ æœ‰æ•ˆ
- âœ… æ¨¡æ€å¯¹é½åœ¨ä¸­æœŸè¾¾åˆ°æœ€ä½³
- âœ… å·²å‡†å¤‡å¥½è¿›å…¥ Stage2

**æ‚¨æåˆ°çš„è­¦å‘Šå¯èƒ½æ¥è‡ªå…¶ä»–æµ‹è¯•è„šæœ¬ï¼Œè€Œéæ­£å¼è®­ç»ƒã€‚æ­£å¼è®­ç»ƒæ—¥å¿—æ˜¾ç¤ºä¸€åˆ‡æ­£å¸¸ï¼**
